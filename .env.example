# Moses Omondi's AI Recruitment Assistant - Environment Configuration
# Copy this file to .env and configure your values

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=1

# Model Configuration
MODEL_PATH=models/moses-recruitment-assistant
BASE_MODEL=NousResearch/Llama-2-7b-chat-hf

# CORS Configuration (for website integration)
CORS_ORIGINS=*
# In production, set specific origins like:
# CORS_ORIGINS=https://yourdomain.com,https://www.yourdomain.com

# Logging Configuration
LOG_LEVEL=INFO
LOG_FORMAT=json

# Performance Configuration
MAX_TOKENS_DEFAULT=400
TEMPERATURE_DEFAULT=0.7
TIMEOUT_SECONDS=30

# Security Configuration
API_KEY_REQUIRED=false
# Set to true in production and provide API keys
# API_KEY=your-secret-api-key

# Health Check Configuration
HEALTH_CHECK_ENABLED=true
HEALTH_CHECK_INTERVAL=30

# Monitoring (optional)
ENABLE_METRICS=false
METRICS_PORT=9090

# Deployment Environment
ENVIRONMENT=development
# Options: development, staging, production

# GPU Configuration
CUDA_VISIBLE_DEVICES=0
# Set to -1 to disable GPU

# Database (optional - for conversation logging)
DATABASE_URL=
# Example: postgresql://user:password@localhost/moses_ai

# External Services (optional)
HUGGINGFACE_TOKEN=
# Required for gated models

# Cache Configuration (optional)
REDIS_URL=
# Example: redis://localhost:6379

# Rate Limiting (production)
RATE_LIMIT_ENABLED=false
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=3600

# Feature Flags
ENABLE_CHAT=true
ENABLE_CAPABILITIES=true
ENABLE_SAMPLE_QUESTIONS=true

# Deployment Specific
CONTAINER_NAME=moses-ai-assistant
CONTAINER_PORT=8000
CONTAINER_MEMORY=8G
